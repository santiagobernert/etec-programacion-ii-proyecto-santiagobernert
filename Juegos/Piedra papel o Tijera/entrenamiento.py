# -*- coding: utf-8 -*-
"""piedra-papel-tijera.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fO5bGCY5w7Eq2FsjZkikWmLWw9OrUc_f
"""

import tensorflow as tf
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras

builder = tfds.builder('rock_paper_scissors')
info = builder.info

info

datos_entrenamiento = tfds.load(name="rock_paper_scissors", split="train")
datos_prueba = tfds.load(name="rock_paper_scissors", split="test")

imagenes_entrenamiento = np.array([example['image'].numpy()[:,:,0] for example in datos_entrenamiento])
etiquetas_entrenamiento = np.array([example['label'].numpy() for example in datos_entrenamiento])

imagenes_prueba = np.array([example['image'].numpy()[:,:,0] for example in datos_prueba])
etiquetas_pruebaa = np.array([example['label'].numpy() for example in datos_prueba])

imagenes_entrenamiento = imagenes_entrenamiento.reshape(2520, 300, 300, 1)
imagenes_prueba = imagenes_prueba.reshape(372, 300, 300, 1)

imagenes_entrenamiento = imagenes_entrenamiento.astype('float32')
imagenes_prueba = imagenes_prueba.astype('float32')

imagenes_entrenamiento /= 255
imagenes_prueba /= 255

print(imagenes_entrenamiento.shape)

modelo = keras.Sequential([
  keras.layers.AveragePooling2D(6,3, input_shape=(300,300,1)), # crea un promedio con las capas de entrada
  keras.layers.Conv2D(64, 3, activation='relu'), # capa de convolucion 
  keras.layers.Conv2D(32, 3, activation='relu'),
  keras.layers.MaxPool2D(2,2), #maximiza el input
  keras.layers.Dropout(0.5), # reduce el sobreajuste
  keras.layers.Flatten(), #reduce los resultados (comprime) de matriz a lista
  keras.layers.Dense(128, activation='relu'), # activacion: positivo o cero
  keras.layers.Dense(3, activation='softmax') # activacion: probabilidad
])

modelo.compile(optimizer='adam',
              loss=keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

historial = modelo.fit(imagenes_entrenamiento, etiquetas_entrenamiento, epochs=5, batch_size=32)

plt.ylabel("Epoca")
plt.xlabel("Perdida")
plt.plot(historial.history["loss"])

modelo.evaluate(imagenes_prueba, etiquetas_pruebaa)

nombres_clases = info.features['label'].names

predicciones = modelo.predict(imagenes_prueba)
  
def graficar_imagen(i, arr_predicciones, etiquetas_reales, imagenes):
  arr_predicciones, etiqueta_real, img = arr_predicciones[i], etiquetas_reales[i], imagenes[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  
  plt.imshow(img[...,0], cmap=plt.cm.binary)

  etiqueta_prediccion = np.argmax(arr_predicciones)
  if etiqueta_prediccion == etiqueta_real:
    color = 'blue'
  else:
    color = 'red'
  
  plt.xlabel("{} {:2.0f}% ({})".format(nombres_clases[etiqueta_prediccion],
                                100*np.max(arr_predicciones),
                                nombres_clases[etiqueta_real]),
                                color=color)
  
def graficar_valor_arreglo(i, arr_predicciones, etiqueta_real):
  arr_predicciones, etiqueta_real = arr_predicciones[i], etiqueta_real[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  #grafica = plt.bar(range(10), arr_predicciones, color="#777777")
  plt.ylim([0, 1]) 
  etiqueta_prediccion = np.argmax(arr_predicciones)
  
  #grafica[etiqueta_prediccion].set_color('red')
  #grafica[etiqueta_real].set_color('blue')
  
filas = 5
columnas = 5
num_imagenes = filas*columnas
plt.figure(figsize=(2*2*columnas, 2*filas))
for i in range(num_imagenes):
  plt.subplot(filas, columnas, i+1)
  graficar_imagen(i, predicciones, etiquetas_pruebaa, imagenes_prueba)